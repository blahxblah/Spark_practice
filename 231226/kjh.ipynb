{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/12/28 17:20:48 WARN Utils: Your hostname, KJH-DESKTOP resolves to a loopback address: 127.0.1.1; using 192.168.69.220 instead (on interface eth0)\n",
      "23/12/28 17:20:48 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/home/kjh/app/spark/3.5.0/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /home/kjh/.ivy2/cache\n",
      "The jars for the packages stored in: /home/kjh/.ivy2/jars\n",
      "com.microsoft.azure#synapseml_2.12 added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-a137282e-5bc8-499e-bcf2-0d49ba16a2f0;1.0\n",
      "\tconfs: [default]\n",
      "\tfound com.microsoft.azure#synapseml_2.12;1.0.2 in central\n",
      "\tfound com.microsoft.azure#synapseml-core_2.12;1.0.2 in central\n",
      "\tfound org.apache.spark#spark-avro_2.12;3.4.1 in central\n",
      "\tfound org.tukaani#xz;1.9 in central\n",
      "\tfound commons-lang#commons-lang;2.6 in central\n",
      "\tfound org.scalactic#scalactic_2.12;3.2.14 in central\n",
      "\tfound org.scala-lang#scala-reflect;2.12.15 in central\n",
      "\tfound io.spray#spray-json_2.12;1.3.5 in central\n",
      "\tfound com.jcraft#jsch;0.1.54 in central\n",
      "\tfound org.apache.httpcomponents.client5#httpclient5;5.1.3 in central\n",
      "\tfound org.apache.httpcomponents.core5#httpcore5;5.1.3 in central\n",
      "\tfound org.apache.httpcomponents.core5#httpcore5-h2;5.1.3 in central\n",
      "\tfound org.slf4j#slf4j-api;1.7.25 in central\n",
      "\tfound commons-codec#commons-codec;1.15 in central\n",
      "\tfound org.apache.httpcomponents#httpmime;4.5.13 in central\n",
      "\tfound org.apache.httpcomponents#httpclient;4.5.13 in central\n",
      "\tfound org.apache.httpcomponents#httpcore;4.4.13 in central\n",
      "\tfound commons-logging#commons-logging;1.2 in central\n",
      "\tfound com.linkedin.isolation-forest#isolation-forest_3.4.1_2.12;3.0.3 in central\n",
      "\tfound com.chuusai#shapeless_2.12;2.3.10 in central\n",
      "\tfound org.testng#testng;6.8.8 in central\n",
      "\tfound org.beanshell#bsh;2.0b4 in central\n",
      "\tfound com.beust#jcommander;1.27 in central\n",
      "\tfound org.scalanlp#breeze_2.12;2.1.0 in central\n",
      "\tfound org.scalanlp#breeze-macros_2.12;2.1.0 in central\n",
      "\tfound org.typelevel#spire_2.12;0.17.0 in central\n",
      "\tfound org.typelevel#spire-macros_2.12;0.17.0 in central\n",
      "\tfound org.typelevel#algebra_2.12;2.0.1 in central\n",
      "\tfound org.typelevel#cats-kernel_2.12;2.1.1 in central\n",
      "\tfound org.typelevel#spire-platform_2.12;0.17.0 in central\n",
      "\tfound org.typelevel#spire-util_2.12;0.17.0 in central\n",
      "\tfound dev.ludovic.netlib#blas;3.0.1 in central\n",
      "\tfound net.sourceforge.f2j#arpack_combined_all;0.1 in central\n",
      "\tfound dev.ludovic.netlib#lapack;3.0.1 in central\n",
      "\tfound dev.ludovic.netlib#arpack;3.0.1 in central\n",
      "\tfound net.sf.opencsv#opencsv;2.3 in central\n",
      "\tfound com.github.wendykierp#JTransforms;3.1 in central\n",
      "\tfound pl.edu.icm#JLargeArrays;1.5 in central\n",
      "\tfound org.apache.commons#commons-math3;3.2 in central\n",
      "\tfound org.scala-lang.modules#scala-collection-compat_2.12;2.7.0 in central\n",
      "\tfound com.microsoft.azure#synapseml-deep-learning_2.12;1.0.2 in central\n",
      "\tfound com.microsoft.azure#synapseml-opencv_2.12;1.0.2 in central\n",
      "\tfound org.openpnp#opencv;3.2.0-1 in central\n",
      "\tfound com.microsoft.azure#onnx-protobuf_2.12;0.9.3 in central\n",
      "\tfound com.microsoft.onnxruntime#onnxruntime_gpu;1.8.1 in central\n",
      "\tfound com.microsoft.azure#synapseml-cognitive_2.12;1.0.2 in central\n",
      "\tfound com.microsoft.cognitiveservices.speech#client-sdk;1.24.1 in central\n",
      "\tfound com.microsoft.azure#synapseml-vw_2.12;1.0.2 in central\n",
      "\tfound com.github.vowpalwabbit#vw-jni;9.3.0 in central\n",
      "\tfound com.microsoft.azure#synapseml-lightgbm_2.12;1.0.2 in central\n",
      "\tfound com.microsoft.ml.lightgbm#lightgbmlib;3.3.510 in central\n",
      ":: resolution report :: resolve 345ms :: artifacts dl 9ms\n",
      "\t:: modules in use:\n",
      "\tcom.beust#jcommander;1.27 from central in [default]\n",
      "\tcom.chuusai#shapeless_2.12;2.3.10 from central in [default]\n",
      "\tcom.github.vowpalwabbit#vw-jni;9.3.0 from central in [default]\n",
      "\tcom.github.wendykierp#JTransforms;3.1 from central in [default]\n",
      "\tcom.jcraft#jsch;0.1.54 from central in [default]\n",
      "\tcom.linkedin.isolation-forest#isolation-forest_3.4.1_2.12;3.0.3 from central in [default]\n",
      "\tcom.microsoft.azure#onnx-protobuf_2.12;0.9.3 from central in [default]\n",
      "\tcom.microsoft.azure#synapseml-cognitive_2.12;1.0.2 from central in [default]\n",
      "\tcom.microsoft.azure#synapseml-core_2.12;1.0.2 from central in [default]\n",
      "\tcom.microsoft.azure#synapseml-deep-learning_2.12;1.0.2 from central in [default]\n",
      "\tcom.microsoft.azure#synapseml-lightgbm_2.12;1.0.2 from central in [default]\n",
      "\tcom.microsoft.azure#synapseml-opencv_2.12;1.0.2 from central in [default]\n",
      "\tcom.microsoft.azure#synapseml-vw_2.12;1.0.2 from central in [default]\n",
      "\tcom.microsoft.azure#synapseml_2.12;1.0.2 from central in [default]\n",
      "\tcom.microsoft.cognitiveservices.speech#client-sdk;1.24.1 from central in [default]\n",
      "\tcom.microsoft.ml.lightgbm#lightgbmlib;3.3.510 from central in [default]\n",
      "\tcom.microsoft.onnxruntime#onnxruntime_gpu;1.8.1 from central in [default]\n",
      "\tcommons-codec#commons-codec;1.15 from central in [default]\n",
      "\tcommons-lang#commons-lang;2.6 from central in [default]\n",
      "\tcommons-logging#commons-logging;1.2 from central in [default]\n",
      "\tdev.ludovic.netlib#arpack;3.0.1 from central in [default]\n",
      "\tdev.ludovic.netlib#blas;3.0.1 from central in [default]\n",
      "\tdev.ludovic.netlib#lapack;3.0.1 from central in [default]\n",
      "\tio.spray#spray-json_2.12;1.3.5 from central in [default]\n",
      "\tnet.sf.opencsv#opencsv;2.3 from central in [default]\n",
      "\tnet.sourceforge.f2j#arpack_combined_all;0.1 from central in [default]\n",
      "\torg.apache.commons#commons-math3;3.2 from central in [default]\n",
      "\torg.apache.httpcomponents#httpclient;4.5.13 from central in [default]\n",
      "\torg.apache.httpcomponents#httpcore;4.4.13 from central in [default]\n",
      "\torg.apache.httpcomponents#httpmime;4.5.13 from central in [default]\n",
      "\torg.apache.httpcomponents.client5#httpclient5;5.1.3 from central in [default]\n",
      "\torg.apache.httpcomponents.core5#httpcore5;5.1.3 from central in [default]\n",
      "\torg.apache.httpcomponents.core5#httpcore5-h2;5.1.3 from central in [default]\n",
      "\torg.apache.spark#spark-avro_2.12;3.4.1 from central in [default]\n",
      "\torg.beanshell#bsh;2.0b4 from central in [default]\n",
      "\torg.openpnp#opencv;3.2.0-1 from central in [default]\n",
      "\torg.scala-lang#scala-reflect;2.12.15 from central in [default]\n",
      "\torg.scala-lang.modules#scala-collection-compat_2.12;2.7.0 from central in [default]\n",
      "\torg.scalactic#scalactic_2.12;3.2.14 from central in [default]\n",
      "\torg.scalanlp#breeze-macros_2.12;2.1.0 from central in [default]\n",
      "\torg.scalanlp#breeze_2.12;2.1.0 from central in [default]\n",
      "\torg.slf4j#slf4j-api;1.7.25 from central in [default]\n",
      "\torg.testng#testng;6.8.8 from central in [default]\n",
      "\torg.tukaani#xz;1.9 from central in [default]\n",
      "\torg.typelevel#algebra_2.12;2.0.1 from central in [default]\n",
      "\torg.typelevel#cats-kernel_2.12;2.1.1 from central in [default]\n",
      "\torg.typelevel#spire-macros_2.12;0.17.0 from central in [default]\n",
      "\torg.typelevel#spire-platform_2.12;0.17.0 from central in [default]\n",
      "\torg.typelevel#spire-util_2.12;0.17.0 from central in [default]\n",
      "\torg.typelevel#spire_2.12;0.17.0 from central in [default]\n",
      "\tpl.edu.icm#JLargeArrays;1.5 from central in [default]\n",
      "\t:: evicted modules:\n",
      "\tcommons-codec#commons-codec;1.11 by [commons-codec#commons-codec;1.15] in [default]\n",
      "\torg.scala-lang.modules#scala-collection-compat_2.12;2.2.0 by [org.scala-lang.modules#scala-collection-compat_2.12;2.7.0] in [default]\n",
      "\torg.apache.commons#commons-math3;3.5 by [org.apache.commons#commons-math3;3.2] in [default]\n",
      "\torg.slf4j#slf4j-api;1.7.5 by [org.slf4j#slf4j-api;1.7.25] in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   55  |   0   |   0   |   4   ||   51  |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-a137282e-5bc8-499e-bcf2-0d49ba16a2f0\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 51 already retrieved (0kB/7ms)\n",
      "23/12/28 17:20:49 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "# 스파크 세션 생성\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# SynapseML : 마이크로소프트에서 만든 스파크용 ML 라이브러리\n",
    "# https://microsoft.github.io/SynapseML/\n",
    "# config에서 synapseml 모듈 불러오기\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Spark study - 231226\") \\\n",
    "    .config(\"spark.jars.packages\", \"com.microsoft.azure:synapseml_2.12:1.0.2\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/12/28 17:20:57 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n"
     ]
    }
   ],
   "source": [
    "# 복잡한 JSON 파일을 읽을 때는 multiline 옵션을 쓰자\n",
    "\n",
    "df_bike = spark.read.option('multiline', 'true').json('file:///home/kjh/data/bike/bike.json')\n",
    "df_weather = spark.read.option('multiline', 'true').json('file:///home/kjh/data/bike/json_cycle_finale.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- useStatus: struct (nullable = true)\n",
      " |    |-- RESULT: struct (nullable = true)\n",
      " |    |    |-- CODE: string (nullable = true)\n",
      " |    |    |-- MESSAGE: string (nullable = true)\n",
      " |    |-- list_total_count: string (nullable = true)\n",
      " |    |-- row: array (nullable = true)\n",
      " |    |    |-- element: struct (containsNull = true)\n",
      " |    |    |    |-- END_INDEX: long (nullable = true)\n",
      " |    |    |    |-- RENT_CNT: string (nullable = true)\n",
      " |    |    |    |-- RENT_NM: string (nullable = true)\n",
      " |    |    |    |-- RTN_CNT: string (nullable = true)\n",
      " |    |    |    |-- START_INDEX: long (nullable = true)\n",
      " |    |    |    |-- STAT_DATA: string (nullable = true)\n",
      " |    |    |    |-- STA_LOC: string (nullable = true)\n",
      "\n",
      "root\n",
      " |-- response: struct (nullable = true)\n",
      " |    |-- body: struct (nullable = true)\n",
      " |    |    |-- dataType: string (nullable = true)\n",
      " |    |    |-- items: struct (nullable = true)\n",
      " |    |    |    |-- item: array (nullable = true)\n",
      " |    |    |    |    |-- element: struct (containsNull = true)\n",
      " |    |    |    |    |    |-- avgCm10Te: string (nullable = true)\n",
      " |    |    |    |    |    |-- avgCm20Te: string (nullable = true)\n",
      " |    |    |    |    |    |-- avgCm30Te: string (nullable = true)\n",
      " |    |    |    |    |    |-- avgCm5Te: string (nullable = true)\n",
      " |    |    |    |    |    |-- avgLmac: string (nullable = true)\n",
      " |    |    |    |    |    |-- avgM05Te: string (nullable = true)\n",
      " |    |    |    |    |    |-- avgM10Te: string (nullable = true)\n",
      " |    |    |    |    |    |-- avgM15Te: string (nullable = true)\n",
      " |    |    |    |    |    |-- avgM30Te: string (nullable = true)\n",
      " |    |    |    |    |    |-- avgM50Te: string (nullable = true)\n",
      " |    |    |    |    |    |-- avgPa: string (nullable = true)\n",
      " |    |    |    |    |    |-- avgPs: string (nullable = true)\n",
      " |    |    |    |    |    |-- avgPv: string (nullable = true)\n",
      " |    |    |    |    |    |-- avgRhm: string (nullable = true)\n",
      " |    |    |    |    |    |-- avgTa: string (nullable = true)\n",
      " |    |    |    |    |    |-- avgTca: string (nullable = true)\n",
      " |    |    |    |    |    |-- avgTd: string (nullable = true)\n",
      " |    |    |    |    |    |-- avgTs: string (nullable = true)\n",
      " |    |    |    |    |    |-- avgWs: string (nullable = true)\n",
      " |    |    |    |    |    |-- ddMefs: string (nullable = true)\n",
      " |    |    |    |    |    |-- ddMefsHrmt: string (nullable = true)\n",
      " |    |    |    |    |    |-- ddMes: string (nullable = true)\n",
      " |    |    |    |    |    |-- ddMesHrmt: string (nullable = true)\n",
      " |    |    |    |    |    |-- hr1MaxIcsr: string (nullable = true)\n",
      " |    |    |    |    |    |-- hr1MaxIcsrHrmt: string (nullable = true)\n",
      " |    |    |    |    |    |-- hr1MaxRn: string (nullable = true)\n",
      " |    |    |    |    |    |-- hr1MaxRnHrmt: string (nullable = true)\n",
      " |    |    |    |    |    |-- hr24SumRws: string (nullable = true)\n",
      " |    |    |    |    |    |-- iscs: string (nullable = true)\n",
      " |    |    |    |    |    |-- maxInsWs: string (nullable = true)\n",
      " |    |    |    |    |    |-- maxInsWsHrmt: string (nullable = true)\n",
      " |    |    |    |    |    |-- maxInsWsWd: string (nullable = true)\n",
      " |    |    |    |    |    |-- maxPs: string (nullable = true)\n",
      " |    |    |    |    |    |-- maxPsHrmt: string (nullable = true)\n",
      " |    |    |    |    |    |-- maxTa: string (nullable = true)\n",
      " |    |    |    |    |    |-- maxTaHrmt: string (nullable = true)\n",
      " |    |    |    |    |    |-- maxWd: string (nullable = true)\n",
      " |    |    |    |    |    |-- maxWs: string (nullable = true)\n",
      " |    |    |    |    |    |-- maxWsHrmt: string (nullable = true)\n",
      " |    |    |    |    |    |-- maxWsWd: string (nullable = true)\n",
      " |    |    |    |    |    |-- mi10MaxRn: string (nullable = true)\n",
      " |    |    |    |    |    |-- mi10MaxRnHrmt: string (nullable = true)\n",
      " |    |    |    |    |    |-- minPs: string (nullable = true)\n",
      " |    |    |    |    |    |-- minPsHrmt: string (nullable = true)\n",
      " |    |    |    |    |    |-- minRhm: string (nullable = true)\n",
      " |    |    |    |    |    |-- minRhmHrmt: string (nullable = true)\n",
      " |    |    |    |    |    |-- minTa: string (nullable = true)\n",
      " |    |    |    |    |    |-- minTaHrmt: string (nullable = true)\n",
      " |    |    |    |    |    |-- minTg: string (nullable = true)\n",
      " |    |    |    |    |    |-- n99Rn: string (nullable = true)\n",
      " |    |    |    |    |    |-- ssDur: string (nullable = true)\n",
      " |    |    |    |    |    |-- stnId: string (nullable = true)\n",
      " |    |    |    |    |    |-- stnNm: string (nullable = true)\n",
      " |    |    |    |    |    |-- sumDpthFhsc: string (nullable = true)\n",
      " |    |    |    |    |    |-- sumFogDur: string (nullable = true)\n",
      " |    |    |    |    |    |-- sumGsr: string (nullable = true)\n",
      " |    |    |    |    |    |-- sumLrgEv: string (nullable = true)\n",
      " |    |    |    |    |    |-- sumRn: string (nullable = true)\n",
      " |    |    |    |    |    |-- sumRnDur: string (nullable = true)\n",
      " |    |    |    |    |    |-- sumSmlEv: string (nullable = true)\n",
      " |    |    |    |    |    |-- sumSsHr: string (nullable = true)\n",
      " |    |    |    |    |    |-- tm: string (nullable = true)\n",
      " |    |    |-- numOfRows: long (nullable = true)\n",
      " |    |    |-- pageNo: long (nullable = true)\n",
      " |    |    |-- totalCount: long (nullable = true)\n",
      " |    |-- header: struct (nullable = true)\n",
      " |    |    |-- resultCode: string (nullable = true)\n",
      " |    |    |-- resultMsg: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 파일의 구조 확인\n",
    "df_bike.printSchema()\n",
    "df_weather.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import explode\n",
    "\n",
    "# 중첩된 JSON 구조 접근 및 explode 함수 사용\n",
    "df_bike = df_bike.select(explode(\"useStatus.row\").alias(\"items\"))\n",
    "df_weather = df_weather.select(explode(\"response.body.items.item\").alias(\"items\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------+\n",
      "|                    items|\n",
      "+-------------------------+\n",
      "| {0, 16, 729. 서부식자...|\n",
      "|  {0, 20, 731. 서울시 ...|\n",
      "|{0, 9, 732. 신월중학교...|\n",
      "|{0, 6, 733. 신정이펜하...|\n",
      "| {0, 13, 734. 신트리공...|\n",
      "| {0, 11, 735. 영도초등...|\n",
      "|{0, 8, 736. 오솔길공원...|\n",
      "| {0, 5, 737. 장수공원,...|\n",
      "| {0, 18, 504. 신자초교...|\n",
      "| {0, 12, 739. 신월사거...|\n",
      "| {0, 2, 740. 으뜸공원,...|\n",
      "| {0, 0, 741. 화곡로 입...|\n",
      "|  {0, 3, 742. 등촌역 5...|\n",
      "| {0, 3, 743. 현대6차아...|\n",
      "| {0, 8, 744. 신목동역 ...|\n",
      "|{0, 3, 745. 강서초등학...|\n",
      "|  {0, 21, 746. 목동2단...|\n",
      "|  {0, 15, 747. 목동3단...|\n",
      "|{0, 3, 748. 목동운동장...|\n",
      "| {0, 38, 505. 자양사거...|\n",
      "+-------------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+--------------------+\n",
      "|               items|\n",
      "+--------------------+\n",
      "|{0.5, 1.9, 2.9, -...|\n",
      "|{0.7, 1.7, 2.6, 0...|\n",
      "|{1.0, 1.8, 2.7, 0...|\n",
      "|{1.1, 1.9, 2.7, 0...|\n",
      "|{1.0, 1.8, 2.6, 0...|\n",
      "|{1.3, 1.9, 2.6, 1...|\n",
      "|{3.8, 3.3, 3.6, 4...|\n",
      "|{4.6, 4.5, 4.7, 4...|\n",
      "|{2.9, 3.6, 4.3, 2...|\n",
      "|{1.8, 2.8, 3.6, 0...|\n",
      "|{1.6, 2.4, 3.2, 0...|\n",
      "|{1.6, 2.3, 3.0, 1...|\n",
      "|{1.1, 2.0, 2.9, 0...|\n",
      "|{0.5, 1.6, 2.5, -...|\n",
      "|{0.2, 1.2, 2.1, -...|\n",
      "|{0.1, 1.0, 1.9, -...|\n",
      "|{0.1, 1.0, 1.8, -...|\n",
      "|{0.1, 1.0, 1.8, -...|\n",
      "|{0.2, 1.0, 1.8, 0...|\n",
      "|{0.5, 1.2, 1.9, 0...|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_bike.show()\n",
    "df_weather.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# items 컬럼의 필드를 별도의 컬럼으로 펼침\n",
    "df_bike = df_bike.select(\"items.*\")\n",
    "df_weather = df_weather.select(\"items.*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bike.createOrReplaceTempView('bike')\n",
    "df_weather.createOrReplaceTempView('weather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 4:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+-------------------------------+-------+-----------+----------+-------+\n",
      "|END_INDEX|RENT_CNT|                        RENT_NM|RTN_CNT|START_INDEX| STAT_DATA|STA_LOC|\n",
      "+---------+--------+-------------------------------+-------+-----------+----------+-------+\n",
      "|        0|      16|     729. 서부식자재마트 건너편|     12|          0|2020-01-01| 양천구|\n",
      "|        0|      20|   731. 서울시 도로환경관리센터|     20|          0|2020-01-01| 양천구|\n",
      "|        0|       9|                732. 신월중학교|      2|          0|2020-01-01| 양천구|\n",
      "|        0|       6|       733. 신정이펜하우스314동|      4|          0|2020-01-01| 양천구|\n",
      "|        0|      13|           734. 신트리공원 입구|     16|          0|2020-01-01| 양천구|\n",
      "|        0|      11|              735. 영도초등학교|     17|          0|2020-01-01| 양천구|\n",
      "|        0|       8|                736. 오솔길공원|      9|          0|2020-01-01| 양천구|\n",
      "|        0|       5|                  737. 장수공원|      5|          0|2020-01-01| 양천구|\n",
      "|        0|      18|        504. 신자초교입구교차로|     21|          0|2020-01-01| 광진구|\n",
      "|        0|      12|                739. 신월사거리|     11|          0|2020-01-01| 양천구|\n",
      "|        0|       2|                  740. 으뜸공원|      6|          0|2020-01-01| 양천구|\n",
      "|        0|       0|        741. 화곡로 입구 교차로|      1|          0|2020-01-01| 양천구|\n",
      "|        0|       3|        742. 등촌역 5번 출구 뒤|      3|          0|2020-01-01| 양천구|\n",
      "|        0|       3|    743. 현대6차아파트 101동 옆|      3|          0|2020-01-01| 양천구|\n",
      "|        0|       8|         744. 신목동역 2번 출구|     13|          0|2020-01-01| 양천구|\n",
      "|        0|       3|              745. 강서초등학교|      4|          0|2020-01-01| 양천구|\n",
      "|        0|      21|            746. 목동2단지 상가|     16|          0|2020-01-01| 양천구|\n",
      "|        0|      15|            747. 목동3단지 상가|     19|          0|2020-01-01| 양천구|\n",
      "|        0|       3|                748. 목동운동장|      3|          0|2020-01-01| 양천구|\n",
      "|        0|      38|505. 자양사거리 광진아크로텔 앞|     40|          0|2020-01-01| 광진구|\n",
      "+---------+--------+-------------------------------+-------+-----------+----------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_bike.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요없어 보이는 컬럼 삭제\n",
    "df_bike = spark.sql(\"\"\"\n",
    "                    SELECT \n",
    "                        RENT_NM, \n",
    "                        CAST(RENT_CNT AS INT) AS RENT_CNT, \n",
    "                        CAST(RTN_CNT AS INT) AS RTN_CNT, \n",
    "                        unix_timestamp(STAT_DATA, 'yyyy-MM-dd') AS STAT_DATA\n",
    "                    FROM bike\n",
    "                    \"\"\")\n",
    "df_weather = df_weather.drop('iscs', 'stnNm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 컬럼의 형식변환\n",
    "# tm 컬럼은 String으로 된 YYYY-MM-DD 날짜 형식. VectorAssembler 을 사용하기 위해서는 숫자로 변환 필요\n",
    "# Date 로 먼저 변환한 뒤, Timestamp 형식으로 변환 => 최종 long 타입\n",
    "\n",
    "from pyspark.sql.functions import col, unix_timestamp, to_date\n",
    "\n",
    "df_wt = df_weather\n",
    "\n",
    "# 'tm' 컬럼을 날짜 타입으로 변환하고, 이를 Unix timestamp로 변환\n",
    "df_wt = df_wt.withColumn('tm', unix_timestamp(to_date(col('tm'), 'yyyy-MM-dd')))\n",
    "\n",
    "data_types = {\n",
    "    \"stnId\": \"int\",  # 지점 번호는 정수\n",
    "    \"avgM15Te\": \"float\",  # 지중온도는 소수점을 포함할 수 있으므로 float\n",
    "    \"n99Rn\": \"float\",  # 강수량은 소수점을 포함할 수 있음\n",
    "    \"minPs\": \"float\",  # 기압은 소수점을 포함할 수 있음\n",
    "    \"avgRhm\": \"float\",  # 상대습도는 소수점을 포함할 수 있음\n",
    "    \"minRhmHrmt\": \"int\",  # 시각은 정수로 처리\n",
    "    \"maxInsWsWd\": \"int\",  # 풍향은 정수로 처리\n",
    "    \"avgTs\": \"float\",  # 지면온도는 소수점을 포함할 수 있음\n",
    "    \"maxInsWsHrmt\": \"int\",  # 시각은 정수로 처리\n",
    "    \"ddMesHrmt\": \"int\",  # 시각은 정수로 처리\n",
    "    \"maxPsHrmt\": \"int\",  # 시각은 정수로 처리\n",
    "    \"avgPv\": \"float\",  # 증기압은 소수점을 포함할 수 있음\n",
    "    \"minRhm\": \"float\",  # 상대습도는 소수점을 포함할 수 있음\n",
    "    \"sumSsHr\": \"float\",  # 일조 시간은 소수점을 포함할 수 있음\n",
    "    \"ssDur\": \"float\",  # 가조시간은 소수점을 포함할 수 있음\n",
    "    \"avgPs\": \"float\",  # 해면기압은 소수점을 포함할 수 있음\n",
    "    \"maxWs\": \"float\",  # 풍속은 소수점을 포함할 수 있음\n",
    "    \"avgCm5Te\": \"float\",  # 지중온도는 소수점을 포함할 수 있음\n",
    "    \"minTg\": \"float\",  # 초상온도는 소수점을 포함할 수 있음\n",
    "    \"maxWsWd\": \"int\",  # 풍향은 정수로 처리\n",
    "    \"sumSmlEv\": \"float\",  # 증발량은 소수점을 포함할 수 있음\n",
    "    \"avgTca\": \"float\",  # 전운량은 소수점을 포함할 수 있음\n",
    "    \"hr1MaxIcsr\": \"float\",  # 일사량은 소수점을 포함할 수 있음\n",
    "    \"avgTd\": \"float\",  # 이슬점온도는 소수점을 포함할 수 있음\n",
    "    \"maxPs\": \"float\",  # 해면기압은 소수점을 포함할 수 있음\n",
    "    \"avgCm20Te\": \"float\",  # 지중온도는 소수점을 포함할 수 있음\n",
    "    \"ddMes\": \"float\",  # 적설량은 소수점을 포함할 수 있음\n",
    "    \"minTa\": \"float\",  # 기온은 소수점을 포함할 수 있음\n",
    "    \"minPsHrmt\": \"int\",  # 시각은 정수로 처리\n",
    "    \"avgM50Te\": \"float\",  # 지중온도는 소수점을 포함할 수 있음\n",
    "    \"maxTa\": \"float\",  # 기온은 소수점을 포함할 수 있음\n",
    "    \"hr24SumRws\": \"int\",  # 풍정합은 정수로 처리\n",
    "    \"avgM30Te\": \"float\",  # 지중온도는 소수점을 포함할 수 있음\n",
    "    \"avgCm10Te\": \"float\",  # 지중온도는 소수점을 포함할 수 있음\n",
    "    \"avgM05Te\": \"float\",  # 지중온도는 소수점을 포함할 수 있음\n",
    "    \"hr1MaxIcsrHrmt\": \"int\",  # 시각은 정수로 처리\n",
    "    \"maxInsWs\": \"float\",  # 풍속은 소수점을 포함할 수 있음\n",
    "    \"avgTca\": \"float\",  # 전운량은 소수점을 포함할 수 있음\n",
    "    \"avgCm30Te\": \"float\",  # 지중온도는 소수점을 포함할 수 있음\n",
    "    \"avgM10Te\": \"float\",  # 지중온도는 소수점을 포함할 수 있음\n",
    "    \"sumGsr\": \"float\",  # 일사량은 소수점을 포함할 수 있음\n",
    "    \"maxWsHrmt\": \"int\",  # 시각은 정수로 처리\n",
    "    \"avgPa\": \"float\",  # 현지기압은 소수점을 포함할 수 있음\n",
    "    \"avgWs\": \"float\",  # 풍속은 소수점을 포함할 수 있음\n",
    "    \"sumFogDur\": \"float\",  # 안개 지속 시간은 소수점을 포함할 수 있음\n",
    "    \"sumLrgEv\": \"float\",  # 증발량은 소수점을 포함할 수 있음\n",
    "    \"sumDpthFhsc\": \"float\",  # 신적설은 소수점을 포함할 수 있음\n",
    "    \"ddMefs\": \"float\",  # 적설량은 소수점을 포함할 수 있음\n",
    "    \"ddMefsHrmt\": \"int\",  # 시각은 정수로 처리\n",
    "    \"sumRn\": \"float\",  # 강수량은 소수점을 포함할 수 있음\n",
    "    \"hr1MaxRnHrmt\": \"int\",  # 시각은 정수로 처리\n",
    "    \"hr1MaxRn\": \"float\",  # 강수량은 소수점을 포함할 수 있음\n",
    "    \"mi10MaxRnHrmt\": \"int\",  # 시각은 정수로 처리\n",
    "    \"mi10MaxRn\": \"float\",  # 강수량은 소수점을 포함할 수 있음\n",
    "    \"avgTa\": \"float\",  # 기온은 소수점을 포함할 수 있음\n",
    "    \"minTaHrmt\": \"int\",  # 시각은 정수로 처리\n",
    "    \"maxTaHrmt\": \"int\",  # 시각은 정수로 처리\n",
    "    \"maxWd\": \"int\",  # 풍향은 정수로 처리\n",
    "    \"avgLmac\": \"float\",  # 중하층운량은 소수점을 포함할 수 있음\n",
    "    \"sumRnDur\": \"float\"\n",
    "}\n",
    "\n",
    "# 딕셔너리 형태의 컬럼 타입정보를 가지고 withColumn을 for문으로 돌림\n",
    "for column, data_type in data_types.items():\n",
    "    df_wt = df_wt.withColumn(column, col(column).cast(data_type))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- RENT_NM: string (nullable = true)\n",
      " |-- RENT_CNT: integer (nullable = true)\n",
      " |-- RTN_CNT: integer (nullable = true)\n",
      " |-- STAT_DATA: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_bike.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결측치 컬럼 제거\n",
    "drop_cols = ['ddMefs', 'ddMefsHrmt', 'ddMes', 'ddMesHrmt', 'hr1MaxRn', 'hr1MaxRnHrmt', 'mi10MaxRn', 'mi10MaxRnHrmt', 'n99Rn', 'sumDpthFhsc', 'sumFogDur', 'sumRn', 'sumRnDur']\n",
    "df_wt = df_wt.drop(*drop_cols)\n",
    "\n",
    "# 결측 데이터 있는 행 제거\n",
    "df_wt = df_wt.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[avgCm10Te: float, avgCm20Te: float, avgCm30Te: float, avgCm5Te: float, avgLmac: float, avgM05Te: float, avgM10Te: float, avgM15Te: float, avgM30Te: float, avgM50Te: float, avgPa: float, avgPs: float, avgPv: float, avgRhm: float, avgTa: float, avgTca: float, avgTd: float, avgTs: float, avgWs: float, hr1MaxIcsr: float, hr1MaxIcsrHrmt: int, hr24SumRws: int, maxInsWs: float, maxInsWsHrmt: int, maxInsWsWd: int, maxPs: float, maxPsHrmt: int, maxTa: float, maxTaHrmt: int, maxWd: int, maxWs: float, maxWsHrmt: int, maxWsWd: int, minPs: float, minPsHrmt: int, minRhm: float, minRhmHrmt: int, minTa: float, minTaHrmt: int, minTg: float, ssDur: float, stnId: int, sumGsr: float, sumLrgEv: float, sumSmlEv: float, sumSsHr: float, tm: bigint]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 캐시를 수행하여 아래의 JOIN 작업의 속도를 최적화\n",
    "\n",
    "df_bike.createOrReplaceTempView('bike')\n",
    "df_wt.createOrReplaceTempView('wt')\n",
    "df_bike.cache()\n",
    "df_wt.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fin = spark.sql(\"\"\"\n",
    "                   SELECT b.*, w.*\n",
    "                   FROM bike b\n",
    "                   INNER JOIN wt w\n",
    "                   ON b.STAT_DATA = w.tm\n",
    "                   \"\"\")\n",
    "\n",
    "df_fin = df_fin.drop(\"tm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 5:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------+--------+-------+----------+---------+---------+---------+--------+-------+--------+--------+--------+--------+--------+------+------+-----+------+-----+------+-----+-----+-----+----------+--------------+----------+--------+------------+----------+------+---------+-----+---------+-----+-----+---------+-------+------+---------+------+----------+-----+---------+-----+-----+-----+------+--------+--------+-------+\n",
      "|                        RENT_NM|RENT_CNT|RTN_CNT| STAT_DATA|avgCm10Te|avgCm20Te|avgCm30Te|avgCm5Te|avgLmac|avgM05Te|avgM10Te|avgM15Te|avgM30Te|avgM50Te| avgPa| avgPs|avgPv|avgRhm|avgTa|avgTca|avgTd|avgTs|avgWs|hr1MaxIcsr|hr1MaxIcsrHrmt|hr24SumRws|maxInsWs|maxInsWsHrmt|maxInsWsWd| maxPs|maxPsHrmt|maxTa|maxTaHrmt|maxWd|maxWs|maxWsHrmt|maxWsWd| minPs|minPsHrmt|minRhm|minRhmHrmt|minTa|minTaHrmt|minTg|ssDur|stnId|sumGsr|sumLrgEv|sumSmlEv|sumSsHr|\n",
      "+-------------------------------+--------+-------+----------+---------+---------+---------+--------+-------+--------+--------+--------+--------+--------+------+------+-----+------+-----+------+-----+-----+-----+----------+--------------+----------+--------+------------+----------+------+---------+-----+---------+-----+-----+---------+-------+------+---------+------+----------+-----+---------+-----+-----+-----+------+--------+--------+-------+\n",
      "|     729. 서부식자재마트 건너편|      16|     12|1577804400|      0.5|      1.9|      2.9|    -0.4|    8.9|     4.1|     7.2|     9.8|    15.3|    17.0|1021.1|1032.1|  3.4|  64.4| -2.2|   8.9| -8.1| -0.9|  0.6|       1.0|          1100|       509|     4.8|         906|        50|1034.0|      952|  0.3|     1457|   50|  2.6|      904|     50|1031.2|     1418|  37.0|         2| -6.5|        1| -6.6|  9.6|  108|  4.53|     0.4|     0.6|    0.8|\n",
      "|   731. 서울시 도로환경관리센터|      20|     20|1577804400|      0.5|      1.9|      2.9|    -0.4|    8.9|     4.1|     7.2|     9.8|    15.3|    17.0|1021.1|1032.1|  3.4|  64.4| -2.2|   8.9| -8.1| -0.9|  0.6|       1.0|          1100|       509|     4.8|         906|        50|1034.0|      952|  0.3|     1457|   50|  2.6|      904|     50|1031.2|     1418|  37.0|         2| -6.5|        1| -6.6|  9.6|  108|  4.53|     0.4|     0.6|    0.8|\n",
      "|                732. 신월중학교|       9|      2|1577804400|      0.5|      1.9|      2.9|    -0.4|    8.9|     4.1|     7.2|     9.8|    15.3|    17.0|1021.1|1032.1|  3.4|  64.4| -2.2|   8.9| -8.1| -0.9|  0.6|       1.0|          1100|       509|     4.8|         906|        50|1034.0|      952|  0.3|     1457|   50|  2.6|      904|     50|1031.2|     1418|  37.0|         2| -6.5|        1| -6.6|  9.6|  108|  4.53|     0.4|     0.6|    0.8|\n",
      "|       733. 신정이펜하우스314동|       6|      4|1577804400|      0.5|      1.9|      2.9|    -0.4|    8.9|     4.1|     7.2|     9.8|    15.3|    17.0|1021.1|1032.1|  3.4|  64.4| -2.2|   8.9| -8.1| -0.9|  0.6|       1.0|          1100|       509|     4.8|         906|        50|1034.0|      952|  0.3|     1457|   50|  2.6|      904|     50|1031.2|     1418|  37.0|         2| -6.5|        1| -6.6|  9.6|  108|  4.53|     0.4|     0.6|    0.8|\n",
      "|           734. 신트리공원 입구|      13|     16|1577804400|      0.5|      1.9|      2.9|    -0.4|    8.9|     4.1|     7.2|     9.8|    15.3|    17.0|1021.1|1032.1|  3.4|  64.4| -2.2|   8.9| -8.1| -0.9|  0.6|       1.0|          1100|       509|     4.8|         906|        50|1034.0|      952|  0.3|     1457|   50|  2.6|      904|     50|1031.2|     1418|  37.0|         2| -6.5|        1| -6.6|  9.6|  108|  4.53|     0.4|     0.6|    0.8|\n",
      "|              735. 영도초등학교|      11|     17|1577804400|      0.5|      1.9|      2.9|    -0.4|    8.9|     4.1|     7.2|     9.8|    15.3|    17.0|1021.1|1032.1|  3.4|  64.4| -2.2|   8.9| -8.1| -0.9|  0.6|       1.0|          1100|       509|     4.8|         906|        50|1034.0|      952|  0.3|     1457|   50|  2.6|      904|     50|1031.2|     1418|  37.0|         2| -6.5|        1| -6.6|  9.6|  108|  4.53|     0.4|     0.6|    0.8|\n",
      "|                736. 오솔길공원|       8|      9|1577804400|      0.5|      1.9|      2.9|    -0.4|    8.9|     4.1|     7.2|     9.8|    15.3|    17.0|1021.1|1032.1|  3.4|  64.4| -2.2|   8.9| -8.1| -0.9|  0.6|       1.0|          1100|       509|     4.8|         906|        50|1034.0|      952|  0.3|     1457|   50|  2.6|      904|     50|1031.2|     1418|  37.0|         2| -6.5|        1| -6.6|  9.6|  108|  4.53|     0.4|     0.6|    0.8|\n",
      "|                  737. 장수공원|       5|      5|1577804400|      0.5|      1.9|      2.9|    -0.4|    8.9|     4.1|     7.2|     9.8|    15.3|    17.0|1021.1|1032.1|  3.4|  64.4| -2.2|   8.9| -8.1| -0.9|  0.6|       1.0|          1100|       509|     4.8|         906|        50|1034.0|      952|  0.3|     1457|   50|  2.6|      904|     50|1031.2|     1418|  37.0|         2| -6.5|        1| -6.6|  9.6|  108|  4.53|     0.4|     0.6|    0.8|\n",
      "|        504. 신자초교입구교차로|      18|     21|1577804400|      0.5|      1.9|      2.9|    -0.4|    8.9|     4.1|     7.2|     9.8|    15.3|    17.0|1021.1|1032.1|  3.4|  64.4| -2.2|   8.9| -8.1| -0.9|  0.6|       1.0|          1100|       509|     4.8|         906|        50|1034.0|      952|  0.3|     1457|   50|  2.6|      904|     50|1031.2|     1418|  37.0|         2| -6.5|        1| -6.6|  9.6|  108|  4.53|     0.4|     0.6|    0.8|\n",
      "|                739. 신월사거리|      12|     11|1577804400|      0.5|      1.9|      2.9|    -0.4|    8.9|     4.1|     7.2|     9.8|    15.3|    17.0|1021.1|1032.1|  3.4|  64.4| -2.2|   8.9| -8.1| -0.9|  0.6|       1.0|          1100|       509|     4.8|         906|        50|1034.0|      952|  0.3|     1457|   50|  2.6|      904|     50|1031.2|     1418|  37.0|         2| -6.5|        1| -6.6|  9.6|  108|  4.53|     0.4|     0.6|    0.8|\n",
      "|                  740. 으뜸공원|       2|      6|1577804400|      0.5|      1.9|      2.9|    -0.4|    8.9|     4.1|     7.2|     9.8|    15.3|    17.0|1021.1|1032.1|  3.4|  64.4| -2.2|   8.9| -8.1| -0.9|  0.6|       1.0|          1100|       509|     4.8|         906|        50|1034.0|      952|  0.3|     1457|   50|  2.6|      904|     50|1031.2|     1418|  37.0|         2| -6.5|        1| -6.6|  9.6|  108|  4.53|     0.4|     0.6|    0.8|\n",
      "|        741. 화곡로 입구 교차로|       0|      1|1577804400|      0.5|      1.9|      2.9|    -0.4|    8.9|     4.1|     7.2|     9.8|    15.3|    17.0|1021.1|1032.1|  3.4|  64.4| -2.2|   8.9| -8.1| -0.9|  0.6|       1.0|          1100|       509|     4.8|         906|        50|1034.0|      952|  0.3|     1457|   50|  2.6|      904|     50|1031.2|     1418|  37.0|         2| -6.5|        1| -6.6|  9.6|  108|  4.53|     0.4|     0.6|    0.8|\n",
      "|        742. 등촌역 5번 출구 뒤|       3|      3|1577804400|      0.5|      1.9|      2.9|    -0.4|    8.9|     4.1|     7.2|     9.8|    15.3|    17.0|1021.1|1032.1|  3.4|  64.4| -2.2|   8.9| -8.1| -0.9|  0.6|       1.0|          1100|       509|     4.8|         906|        50|1034.0|      952|  0.3|     1457|   50|  2.6|      904|     50|1031.2|     1418|  37.0|         2| -6.5|        1| -6.6|  9.6|  108|  4.53|     0.4|     0.6|    0.8|\n",
      "|    743. 현대6차아파트 101동 옆|       3|      3|1577804400|      0.5|      1.9|      2.9|    -0.4|    8.9|     4.1|     7.2|     9.8|    15.3|    17.0|1021.1|1032.1|  3.4|  64.4| -2.2|   8.9| -8.1| -0.9|  0.6|       1.0|          1100|       509|     4.8|         906|        50|1034.0|      952|  0.3|     1457|   50|  2.6|      904|     50|1031.2|     1418|  37.0|         2| -6.5|        1| -6.6|  9.6|  108|  4.53|     0.4|     0.6|    0.8|\n",
      "|         744. 신목동역 2번 출구|       8|     13|1577804400|      0.5|      1.9|      2.9|    -0.4|    8.9|     4.1|     7.2|     9.8|    15.3|    17.0|1021.1|1032.1|  3.4|  64.4| -2.2|   8.9| -8.1| -0.9|  0.6|       1.0|          1100|       509|     4.8|         906|        50|1034.0|      952|  0.3|     1457|   50|  2.6|      904|     50|1031.2|     1418|  37.0|         2| -6.5|        1| -6.6|  9.6|  108|  4.53|     0.4|     0.6|    0.8|\n",
      "|              745. 강서초등학교|       3|      4|1577804400|      0.5|      1.9|      2.9|    -0.4|    8.9|     4.1|     7.2|     9.8|    15.3|    17.0|1021.1|1032.1|  3.4|  64.4| -2.2|   8.9| -8.1| -0.9|  0.6|       1.0|          1100|       509|     4.8|         906|        50|1034.0|      952|  0.3|     1457|   50|  2.6|      904|     50|1031.2|     1418|  37.0|         2| -6.5|        1| -6.6|  9.6|  108|  4.53|     0.4|     0.6|    0.8|\n",
      "|            746. 목동2단지 상가|      21|     16|1577804400|      0.5|      1.9|      2.9|    -0.4|    8.9|     4.1|     7.2|     9.8|    15.3|    17.0|1021.1|1032.1|  3.4|  64.4| -2.2|   8.9| -8.1| -0.9|  0.6|       1.0|          1100|       509|     4.8|         906|        50|1034.0|      952|  0.3|     1457|   50|  2.6|      904|     50|1031.2|     1418|  37.0|         2| -6.5|        1| -6.6|  9.6|  108|  4.53|     0.4|     0.6|    0.8|\n",
      "|            747. 목동3단지 상가|      15|     19|1577804400|      0.5|      1.9|      2.9|    -0.4|    8.9|     4.1|     7.2|     9.8|    15.3|    17.0|1021.1|1032.1|  3.4|  64.4| -2.2|   8.9| -8.1| -0.9|  0.6|       1.0|          1100|       509|     4.8|         906|        50|1034.0|      952|  0.3|     1457|   50|  2.6|      904|     50|1031.2|     1418|  37.0|         2| -6.5|        1| -6.6|  9.6|  108|  4.53|     0.4|     0.6|    0.8|\n",
      "|                748. 목동운동장|       3|      3|1577804400|      0.5|      1.9|      2.9|    -0.4|    8.9|     4.1|     7.2|     9.8|    15.3|    17.0|1021.1|1032.1|  3.4|  64.4| -2.2|   8.9| -8.1| -0.9|  0.6|       1.0|          1100|       509|     4.8|         906|        50|1034.0|      952|  0.3|     1457|   50|  2.6|      904|     50|1031.2|     1418|  37.0|         2| -6.5|        1| -6.6|  9.6|  108|  4.53|     0.4|     0.6|    0.8|\n",
      "|505. 자양사거리 광진아크로텔 앞|      38|     40|1577804400|      0.5|      1.9|      2.9|    -0.4|    8.9|     4.1|     7.2|     9.8|    15.3|    17.0|1021.1|1032.1|  3.4|  64.4| -2.2|   8.9| -8.1| -0.9|  0.6|       1.0|          1100|       509|     4.8|         906|        50|1034.0|      952|  0.3|     1457|   50|  2.6|      904|     50|1031.2|     1418|  37.0|         2| -6.5|        1| -6.6|  9.6|  108|  4.53|     0.4|     0.6|    0.8|\n",
      "+-------------------------------+--------+-------+----------+---------+---------+---------+--------+-------+--------+--------+--------+--------+--------+------+------+-----+------+-----+------+-----+-----+-----+----------+--------------+----------+--------+------------+----------+------+---------+-----+---------+-----+-----+---------+-------+------+---------+------+----------+-----+---------+-----+-----+-----+------+--------+--------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_fin.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline 모듈을 사용하여 라벨 인코딩 + 원핫인코딩 + 벡터어셈블러 한번에 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:6: SyntaxWarning: invalid escape sequence '\\['\n",
      "<>:6: SyntaxWarning: invalid escape sequence '\\['\n",
      "/tmp/ipykernel_72680/3289084467.py:6: SyntaxWarning: invalid escape sequence '\\['\n",
      "  df_fin = df_fin.withColumn('RENT_NM', regexp_replace('RENT_NM', \"[ ,:;{}()\\[\\]\\\\n]\", \"_\"))\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Using too small ``bin_construct_sample_cnt`` may encounter unexpected errors and poor accuracy.\n",
      "[LightGBM] [Info] Saving data reference to binary buffer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql.functions import regexp_replace\n",
    "\n",
    "# 예시: 'RENT_NM' 컬럼의 특수 문자를 '_'로 대체\n",
    "df_fin = df_fin.withColumn('RENT_NM', regexp_replace('RENT_NM', \"[ ,:;{}()\\[\\]\\\\n]\", \"_\"))\n",
    "\n",
    "# StringIndexer를 사용하여 범주형 컬럼을 숫자형으로 변환\n",
    "stringIndexer = StringIndexer(inputCol=\"RENT_NM\", outputCol=\"indexed_RENT_NM\", handleInvalid=\"keep\")\n",
    "\n",
    "# OneHotEncoder를 사용하여 숫자 인덱스를 원-핫 인코딩된 벡터로 변환\n",
    "oneHotEncoder = OneHotEncoder(inputCols=[\"indexed_RENT_NM\"], outputCols=[\"encoded_RENT_NM\"])\n",
    "\n",
    "# 데이터프레임의 모든 컬럼을 특성으로 사용하고자 할 때\n",
    "features = df_fin.columns\n",
    "\n",
    "# 라벨 컬럼과 원본 범주형 컬럼 제외\n",
    "features.remove('RENT_CNT')\n",
    "features.remove('RENT_NM')\n",
    "\n",
    "# StringIndexer와 OneHotEncoder의 출력 컬럼 추가\n",
    "features.append('encoded_RENT_NM')\n",
    "\n",
    "# VectorAssembler 생성\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=features,\n",
    "    outputCol=\"features\"\n",
    ")\n",
    "\n",
    "# # 파이프라인 생성 및 모델 학습\n",
    "# pipeline = Pipeline(stages=[stringIndexer, oneHotEncoder, assembler])\n",
    "# transformer = pipeline.fit(df_fin)\n",
    "# tf_df = transformer.transform(df_fin).select('RENT_CNT', 'features')\n",
    "\n",
    "# train, test 쪼개기\n",
    "train, test = df_fin.randomSplit([0.7, 0.3], seed=42)\n",
    "\n",
    "from synapse.ml.lightgbm import LightGBMRegressor\n",
    "\n",
    "# 모델 생성 및 훈련\n",
    "lgbm = LightGBMRegressor(objective='regression',\n",
    "                            featuresCol='features',\n",
    "                            labelCol='RENT_CNT',\n",
    "                            alpha=0.3,\n",
    "                            learningRate=0.3,\n",
    "                            numIterations=100,\n",
    "                            numLeaves=31)\n",
    "\n",
    "# 파이프라인 생성 및 모델 학습\n",
    "pipeline = Pipeline(stages=[stringIndexer, oneHotEncoder, assembler, lgbm])\n",
    "model = pipeline.fit(train)\n",
    "pred = model.transform(test).select('RENT_CNT', 'features', 'prediction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/12/28 17:43:41 WARN DAGScheduler: Broadcasting large task binary with size 1043.5 KiB\n",
      "[Stage 55:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+------------------+\n",
      "|RENT_CNT|            features|        prediction|\n",
      "+--------+--------------------+------------------+\n",
      "|       8|(2059,[0,1,2,3,4,...|7.6577393118617065|\n",
      "|       5|(2059,[0,1,2,3,4,...| 6.311127688719191|\n",
      "|       8|(2059,[0,1,2,3,4,...|13.663889560101062|\n",
      "|       1|(2059,[1,2,3,4,5,...|1.0241257224240277|\n",
      "|       4|(2059,[0,1,2,3,4,...| 6.311127688719191|\n",
      "|       4|(2059,[0,1,2,3,4,...|12.024529905375973|\n",
      "|      13|(2059,[0,1,2,3,4,...|7.6577393118617065|\n",
      "|       1|(2059,[0,1,2,3,4,...|3.3093776985709087|\n",
      "|       1|(2059,[1,2,3,4,5,...|0.9378704184666075|\n",
      "|      10|(2059,[0,1,2,3,4,...| 18.67478755093297|\n",
      "|      12|(2059,[0,1,2,3,4,...|10.040706393067522|\n",
      "|      21|(2059,[0,1,2,3,4,...|10.040706393067522|\n",
      "|      27|(2059,[0,1,2,3,4,...|  29.6503145517171|\n",
      "|       0|(2059,[0,1,2,3,4,...|2.3239241299267204|\n",
      "|       1|(2059,[0,1,2,3,4,...| 4.365128044620229|\n",
      "|       4|(2059,[0,1,2,3,4,...| 6.056571172347212|\n",
      "|       4|(2059,[0,1,2,3,4,...|7.6577393118617065|\n",
      "|       5|(2059,[0,1,2,3,4,...| 6.385652238309573|\n",
      "|       5|(2059,[0,1,2,3,4,...|10.670463777860936|\n",
      "|       6|(2059,[0,1,2,3,4,...| 8.758846866423632|\n",
      "+--------+--------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "pred.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # train, test 쪼개기\n",
    "# train, test = tf_df.randomSplit([0.7, 0.3], seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from synapse.ml.lightgbm import LightGBMRegressor\n",
    "\n",
    "# # 모델 생성 및 훈련\n",
    "# lgbm = LightGBMRegressor(objective='regression',\n",
    "#                             featuresCol='features',\n",
    "#                             labelCol='RENT_CNT',\n",
    "#                             alpha=0.3,\n",
    "#                             learningRate=0.3,\n",
    "#                             numIterations=100,\n",
    "#                             numLeaves=31)\n",
    "\n",
    "# model = lgbm.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 예측\n",
    "# pred = model.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'PipelineModel' object has no attribute 'getPredictionCol'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# predictionCol 확인\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetPredictionCol\u001b[49m()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'PipelineModel' object has no attribute 'getPredictionCol'"
     ]
    }
   ],
   "source": [
    "# predictionCol 확인\n",
    "model.getPredictionCol()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/12/28 17:44:00 WARN DAGScheduler: Broadcasting large task binary with size 1071.7 KiB\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "# 검증\n",
    "evaluator = RegressionEvaluator(labelCol=\"RENT_CNT\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "# evaluator = RegressionEvaluator(labelCol=\"RENT_CNT\", predictionCol=\"prediction\", metricName=\"r2\")\n",
    "\n",
    "rmse = evaluator.evaluate(pred)\n",
    "# r2 = evaluator.evaluate(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.93899029498106"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse\n",
    "# r2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SynapseML의 AutoML 모듈 사용하여 최적 모델 찾기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from synapse.ml.automl import *\n",
    "from pyspark.ml.regression import RandomForestRegressor\n",
    "from synapse.ml.train import TrainRegressor\n",
    "\n",
    "# 알고리즘 설정\n",
    "rf = RandomForestRegressor()\n",
    "lgbm = LightGBMRegressor()\n",
    "\n",
    "smlmodels = [rf, lgbm]\n",
    "mmlmodels = [TrainRegressor(model=model, labelCol=\"RENT_CNT\") for model in smlmodels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([(Param(parent='RandomForestRegressor_74b102b7e533', name='numTrees', doc='Number of trees to train (>= 1).'), (RandomForestRegressor_74b102b7e533, <synapse.ml.automl.HyperparamBuilder.DiscreteHyperParam object at 0x7f463b6c9130>)), (Param(parent='RandomForestRegressor_74b102b7e533', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes. Must be in range [0, 30].'), (RandomForestRegressor_74b102b7e533, <synapse.ml.automl.HyperparamBuilder.DiscreteHyperParam object at 0x7f463b5f3050>)), (Param(parent='LightGBMRegressor_88aab75b9b20', name='learningRate', doc='Learning rate or shrinkage rate'), (LightGBMRegressor_88aab75b9b20, <synapse.ml.automl.HyperparamBuilder.RangeHyperParam object at 0x7f463b5af0e0>)), (Param(parent='LightGBMRegressor_88aab75b9b20', name='numLeaves', doc='Number of leaves'), (LightGBMRegressor_88aab75b9b20, <synapse.ml.automl.HyperparamBuilder.DiscreteHyperParam object at 0x7f463b5af080>))])\n",
      "<synapse.ml.automl.HyperparamBuilder.RandomSpace object at 0x7f463b5aef30>\n"
     ]
    }
   ],
   "source": [
    "# 각 알고리즘의 하이퍼파라미터 설정\n",
    "paramBuilder  = (\n",
    "    HyperparamBuilder() \n",
    "    .addHyperparam(rf, rf.numTrees, DiscreteHyperParam([10, 20])) \n",
    "    .addHyperparam(rf, rf.maxDepth, DiscreteHyperParam([5, 10])) \n",
    "    .addHyperparam(lgbm, lgbm.learningRate, RangeHyperParam(0.1, 0.3)) \n",
    "    .addHyperparam(lgbm, lgbm.numLeaves, DiscreteHyperParam([31, 50])) \n",
    ")\n",
    "\n",
    "searchSpace = paramBuilder.build()\n",
    "randomSpace = RandomSpace(searchSpace)\n",
    "print(searchSpace)\n",
    "print(randomSpace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/12/28 16:43:26 WARN DAGScheduler: Broadcasting large task binary with size 1045.6 KiB\n",
      "[Stage 40:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Saving data reference to binary buffer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/12/28 16:43:28 WARN DAGScheduler: Broadcasting large task binary with size 1200.5 KiB\n",
      "23/12/28 16:43:39 WARN DAGScheduler: Broadcasting large task binary with size 1286.4 KiB\n",
      "23/12/28 16:43:42 WARN DAGScheduler: Broadcasting large task binary with size 1294.7 KiB\n",
      "23/12/28 16:43:45 WARN DAGScheduler: Broadcasting large task binary with size 1109.3 KiB\n",
      "23/12/28 16:43:54 WARN DAGScheduler: Broadcasting large task binary with size 1235.3 KiB\n",
      "23/12/28 16:44:05 WARN DAGScheduler: Broadcasting large task binary with size 1487.0 KiB\n",
      "23/12/28 16:44:18 WARN DAGScheduler: Broadcasting large task binary with size 1990.5 KiB\n",
      "23/12/28 16:44:33 WARN DAGScheduler: Broadcasting large task binary with size 2.9 MiB\n",
      "23/12/28 16:44:49 WARN DAGScheduler: Broadcasting large task binary with size 4.7 MiB\n",
      "23/12/28 16:45:07 WARN DAGScheduler: Broadcasting large task binary with size 7.8 MiB\n",
      "23/12/28 16:45:30 WARN DAGScheduler: Broadcasting large task binary with size 12.5 MiB\n",
      "23/12/28 16:45:56 WARN DAGScheduler: Broadcasting large task binary with size 18.7 MiB\n",
      "23/12/28 16:46:32 WARN DAGScheduler: Broadcasting large task binary with size 1045.6 KiB\n",
      "23/12/28 16:46:33 WARN DAGScheduler: Broadcasting large task binary with size 1200.5 KiB\n",
      "23/12/28 16:46:45 WARN DAGScheduler: Broadcasting large task binary with size 1288.3 KiB\n",
      "23/12/28 16:46:47 WARN DAGScheduler: Broadcasting large task binary with size 1296.6 KiB\n",
      "23/12/28 16:46:51 WARN DAGScheduler: Broadcasting large task binary with size 1109.3 KiB\n",
      "23/12/28 16:47:01 WARN DAGScheduler: Broadcasting large task binary with size 1235.3 KiB\n",
      "23/12/28 16:47:13 WARN DAGScheduler: Broadcasting large task binary with size 1486.9 KiB\n",
      "23/12/28 16:47:25 WARN DAGScheduler: Broadcasting large task binary with size 1987.3 KiB\n",
      "23/12/28 16:47:39 WARN DAGScheduler: Broadcasting large task binary with size 2.9 MiB\n",
      "23/12/28 16:47:56 WARN DAGScheduler: Broadcasting large task binary with size 4.7 MiB\n",
      "23/12/28 16:48:15 WARN DAGScheduler: Broadcasting large task binary with size 7.6 MiB\n",
      "23/12/28 16:48:37 WARN DAGScheduler: Broadcasting large task binary with size 12.0 MiB\n",
      "ERROR:root:KeyboardInterrupt while sending command.                 (0 + 1) / 1]\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/kjh/.local/share/virtualenvs/kjh-4pV5HF-C/lib/python3.12/site-packages/py4j/java_gateway.py\", line 1038, in send_command\n",
      "    response = connection.send_command(command)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/kjh/.local/share/virtualenvs/kjh-4pV5HF-C/lib/python3.12/site-packages/py4j/clientserver.py\", line 511, in send_command\n",
      "    answer = smart_decode(self.stream.readline()[:-1])\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/kjh/.pyenv/versions/3.12.1/lib/python3.12/socket.py\", line 707, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 13\u001b[0m\n\u001b[1;32m      2\u001b[0m automl \u001b[38;5;241m=\u001b[39m TuneHyperparameters(\n\u001b[1;32m      3\u001b[0m     evaluationMetric\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrmse\u001b[39m\u001b[38;5;124m\"\u001b[39m,            \u001b[38;5;66;03m## 검증방식 설정\u001b[39;00m\n\u001b[1;32m      4\u001b[0m     models\u001b[38;5;241m=\u001b[39mmmlmodels,                   \u001b[38;5;66;03m## 모델 알고리즘 설정\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      9\u001b[0m     seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m                             \u001b[38;5;66;03m## 난수 로직 설정\u001b[39;00m\n\u001b[1;32m     10\u001b[0m )\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# 모델 학습\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m fittedModel \u001b[38;5;241m=\u001b[39m \u001b[43mautoml\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/kjh-4pV5HF-C/lib/python3.12/site-packages/pyspark/ml/base.py:205\u001b[0m, in \u001b[0;36mEstimator.fit\u001b[0;34m(self, dataset, params)\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy(params)\u001b[38;5;241m.\u001b[39m_fit(dataset)\n\u001b[1;32m    204\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 205\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    207\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    208\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mParams must be either a param map or a list/tuple of param maps, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    209\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut got \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mtype\u001b[39m(params)\n\u001b[1;32m    210\u001b[0m     )\n",
      "File \u001b[0;32m/tmp/spark-3c6b7d7c-1c54-4e75-a1a3-6eaf8709694a/userFiles-023f35af-8d9c-482f-958a-e7a86430ac2f/com.microsoft.azure_synapseml-core_2.12-1.0.2.jar/synapse/ml/automl/TuneHyperparameters.py:237\u001b[0m, in \u001b[0;36mTuneHyperparameters._fit\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_fit\u001b[39m(\u001b[38;5;28mself\u001b[39m, dataset):\n\u001b[0;32m--> 237\u001b[0m     java_model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_java\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    238\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_model(java_model)\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/kjh-4pV5HF-C/lib/python3.12/site-packages/pyspark/ml/wrapper.py:378\u001b[0m, in \u001b[0;36mJavaEstimator._fit_java\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    375\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_java_obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    377\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transfer_params_to_java()\n\u001b[0;32m--> 378\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_java_obj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jdf\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/kjh-4pV5HF-C/lib/python3.12/site-packages/py4j/java_gateway.py:1321\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1314\u001b[0m args_command, temp_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_args(\u001b[38;5;241m*\u001b[39margs)\n\u001b[1;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[0;32m-> 1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_command\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m get_return_value(\n\u001b[1;32m   1323\u001b[0m     answer, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_id, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname)\n\u001b[1;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/kjh-4pV5HF-C/lib/python3.12/site-packages/py4j/java_gateway.py:1038\u001b[0m, in \u001b[0;36mGatewayClient.send_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m   1036\u001b[0m connection \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_connection()\n\u001b[1;32m   1037\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1038\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_command\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1039\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m binary:\n\u001b[1;32m   1040\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m response, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_connection_guard(connection)\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/kjh-4pV5HF-C/lib/python3.12/site-packages/py4j/clientserver.py:511\u001b[0m, in \u001b[0;36mClientServerConnection.send_command\u001b[0;34m(self, command)\u001b[0m\n\u001b[1;32m    509\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    510\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 511\u001b[0m         answer \u001b[38;5;241m=\u001b[39m smart_decode(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m    512\u001b[0m         logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAnswer received: \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(answer))\n\u001b[1;32m    513\u001b[0m         \u001b[38;5;66;03m# Happens when a the other end is dead. There might be an empty\u001b[39;00m\n\u001b[1;32m    514\u001b[0m         \u001b[38;5;66;03m# answer before the socket raises an error.\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.1/lib/python3.12/socket.py:707\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    705\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 707\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    708\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    709\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 99:>                                                         (0 + 1) / 1]\r"
     ]
    }
   ],
   "source": [
    "# AutoML 설정\n",
    "automl = TuneHyperparameters(\n",
    "    evaluationMetric=\"rmse\",            ## 검증방식 설정\n",
    "    models=mmlmodels,                   ## 모델 알고리즘 설정\n",
    "    numFolds=2,                         ## 교차 검증 폴드 수\n",
    "    numRuns=len(mmlmodels),             ## 랜덤 서치 횟수\n",
    "    parallelism=3,                      ## 병렬로 실행할 모델의 수\n",
    "    paramSpace=randomSpace.space(),     ## 하이퍼파라미터 공간을 정의하는 객체\n",
    "    seed=42                             ## 난수 로직 설정\n",
    ")\n",
    "\n",
    "# 모델 학습\n",
    "fittedModel = automl.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bootstrap: true, cacheNodeIds: false, checkpointInterval: 10, featureSubsetStrategy: auto, featuresCol: TrainRegressor_6a97b1b2d846_features, impurity: variance, labelCol: RENT_CNT, leafCol: , maxBins: 32, maxDepth: 10, maxMemoryInMB: 256, minInfoGain: 0.0, minInstancesPerNode: 1, minWeightFractionPerNode: 0.0, numTrees: 20, predictionCol: prediction, seed: 1863985136697319306, subsamplingRate: 1.0'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 최적화된 모델의 세부 정보\n",
    "fittedModel.getBestModelInfo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TrainedRegressorModel_652c4df4b9f4"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 최적화된 모델 보기\n",
    "fittedModel.getBestModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최적화된 모델 저장\n",
    "bestModel = fittedModel.getBestModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_squared_error</th>\n",
       "      <th>root_mean_squared_error</th>\n",
       "      <th>R^2</th>\n",
       "      <th>mean_absolute_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>138.786214</td>\n",
       "      <td>11.780756</td>\n",
       "      <td>0.921705</td>\n",
       "      <td>6.37007</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_squared_error  root_mean_squared_error       R^2  mean_absolute_error\n",
       "0          138.786214                11.780756  0.921705              6.37007"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from synapse.ml.train import ComputeModelStatistics\n",
    "\n",
    "prediction = bestModel.transform(test)\n",
    "\n",
    "# ComputeModelStatistics를 사용하여 검증\n",
    "metrics = ComputeModelStatistics().transform(prediction)\n",
    "metrics.limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# 검증\n",
    "evaluator_automl = RegressionEvaluator(labelCol=\"RENT_CNT\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "# evaluator_automl = RegressionEvaluator(labelCol=\"RENT_CNT\", predictionCol=\"prediction\", metricName=\"r2\")\n",
    "\n",
    "rmse_automl = evaluator_automl.evaluate(prediction)\n",
    "# r2_automl = evaluator.evaluate(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11.780756087904537"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse_automl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kjh-4pV5HF-C",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
